%
% File acl2016.tex
%
%% Based on the style files for ACL-2015, with some improvements
%%  taken from the NAACL-2016 style
%% Based on the style files for ACL-2014, which were, in turn,
%% Based on the style files for ACL-2013, which were, in turn,
%% Based on the style files for ACL-2012, which were, in turn,
%% based on the style files for ACL-2011, which were, in turn, 
%% based on the style files for ACL-2010, which were, in turn, 
%% based on the style files for ACL-IJCNLP-2009, which were, in turn,
%% based on the style files for EACL-2009 and IJCNLP-2008...

%% Based on the style files for EACL 2006 by 
%%e.agirre@ehu.es or Sergi.Balari@uab.es
%% and that of ACL 08 by Joakim Nivre and Noah Smith

\documentclass[11pt]{article}
\usepackage{acl2016}
\usepackage{times}
\usepackage{url}
\usepackage{latexsym}

%\aclfinalcopy % Uncomment this line for the final submission
%\def\aclpaperid{***} %  Enter the acl Paper ID here

%\setlength\titlebox{5cm}
% You can expand the titlebox if you need extra space
% to show all the authors. Please do not make the titlebox
% smaller than 5cm (the original size); we will check this
% in the camera-ready version and ask you to change it back.

\newcommand\BibTeX{B{\sc ib}\TeX}

\title{Investigating the Components of Linguistic Accommodation}

\author{First Author \\
  Affiliation / Address line 1 \\
  Affiliation / Address line 2 \\
  Affiliation / Address line 3 \\
  {\tt email@domain} \\\And
  Second Author \\
  Affiliation / Address line 1 \\
  Affiliation / Address line 2 \\
  Affiliation / Address line 3 \\
  {\tt email@domain} \\}

\date{}

\begin{document}
\maketitle
\begin{abstract}
In conversation, people tend to ``accommodate'' or ``align'' to their partners, adopting similar styles of speech.  This accommodation is robust, appearing across many features, and its degree correlates with important social factors such as power and likability, even for non-human accommodators. We focus on ``linguistic alignment'', the amount that one's word use is influenced by others. While there are a variety of computational measures for assessing this alignment, they have not delved into the different components of linguistic alignment. We propose an extension to one of these measures to account for alignment in messages of various lengths, and to separate out the influence of words and word categories within alignment behaviors. We compare alignment behaviors on Twitter with those of the telephone conversations in Switchboard, and show substantial differences between the datasets. Furthermore, we find that different discourse acts also have different alignment behavior in Switchboard.
\end{abstract}


\section{Introduction}
In conversation, people tend to adapt to each other across a broad range of behaviors, collectively known as ``communication accommodation'' \cite{GilesCouplandCoupland1991}. Linguistic alignment, using similar words to one's interlocutor, is one prominent form of accommodation.  It is a robust form of accommodation, found in many settings, including computer-mediated and web-based conversation (Giles, Pennebaker, DNM). It is also interesting because the strength of this alignment varies with important sociological factors, such as power, network centrality, and likability, and may be a useful way of inferring these factors in situations where they are unobserved.

Roughly speaking, linguistic alignment can be measured as the change in likelihood of using a given ``marker'' -- most often a word category (e.g., prepositions or negations) or individual words (e.g., \textit{it}, \textit{the}) -- based on its use by a conversational partner. For instance, an exchange where Alice tells a group ``I like to cook'' and Bob replies ``We love to eat'', could be evidence of Bob aligning to Alice in using pronouns (\textit{I/we}), in using prepositions (\textit{to/to}), and in using the specific word \textit{to}.

While substantial work has suggested that linguistic alignment is important, there are a number of open questions about the nature of this alignment. One is the issue of different components of linguistic accommodation. While linguistic alignment has been studied in multiple ways, the most prominent strand has focused on the level of word categories, looking at how interlocutors change their frequency of using, for instance, pronouns or quantitative words. But alignment can occur at many levels, including individual words \cite{FusaroliEtAl2012?}, of syntactic structure \cite{HealeyPurverHowes2014}, and message length \cite{?}.  There are conflicting expectations about how different types of linguistic alignment should interact, ranging from the Interactive Alignment Model's expectation that different types of alignment should be approximately uniform \cite{PickeringGarrod2004} to arguments that, for instance, lexical and syntactic alignment may push in different directions (Healey et al).  We propose a method that uses the same framework to look at three different levels of alignment: word, category, and category-not-word alignments, defined in Section \ref{sect:alignment-levels}.

A second major question is how the desire to align, which repeats preceding words and concepts, is balanced against a need to move the conversation forward by introducing new words and concepts.  We propose that linguistic alignment is modulated by the discourse act being performed, with certain acts showing greater or lesser alignment depending on their purpose within the conversation.  In particular, we examine the influence of back-channels, short utterances communicating agreement, understanding, or misunderstanding on alignment.

To address these questions, we propose a new version of an existing measure of linguistic alignment, increasing its robustness to messages of different lengths.  We also extend the measure to consider multiple levels of alignment.  We perform two experiments. First, we look at the differences in estimated alignment at the different levels, and show that alignment varies substantially by representation level.  Second, we estimate alignment on different subsets of the Switchboard corpus of telephone conversations, finding that alignment is highly dependent what discourse actions are being undertaken.

\section{Previous Work}

\subsection{Why does alignment matter?}
Linguistic alignment, like other kinds of accommodation, can be a critical part of achieving social goals.  Performance in a variety of cooperative decision-making tasks has been positively related to the participants' linguistic convergence \cite{FusaroliEtAl2012,KacewiczEtAl2013}.  Match-matching in speed dating as well as stability in established relationships have been linked to increased alignment \cite{IrelandEtAl2011}.  Alignment can also improve perceived persuasiveness, encouraging listeners to follow good health practices \cite{KlineCeropski1984} or to leave larger tips \cite{vanBaarenEtAl2003}.

Alignment is also important as an indicator of implicit sociological variables. Less powerful conversants generally accommodate more to powerful conversants. Prominent examples include interviews and jury trials \cite{WillemynsEtAl1997,Gnisci2005,DNMEtAl2012}.  A similar effect is found for network structure: speakers align more to more network-central speakers \cite{NobleFernandez2015}.  Additionally, factors such as gender, likability, respect, and attraction all interact with the magnitude of accommodation \cite{BilousKrauss1988,Natale1975}. Such differences in accommodation can also be indicative of changes to the power dynamic: In U.S. Supreme Court transcripts, \cite{guo2015} showed that depending on the accommodation dimension, justices -- who are more powerful by any intuitive assessment -- may nevertheless accommodate more to lawyers, perhaps because the lawyers have the local power to answer justices' questions.

\subsection{What's the nature of alignment?}
The preceding results show that linguistic alignment is a robust phenomenon, but the specific nature of this alignment is something of a black box. One major question is how different structural levels of language align. The Interactive Alignment Model \cite{PickeringGarrod2004} makes the theoretical claim that alignment should be similar across all structural levels as conversants increasingly share their representation. However, \cite{HealeyPurverHowes2014} find in phone conversations that speakers syntactically diverge from their interlocutors once lexical alignment is accounted for.  Because most work on alignment has been done either on categories of words or aggregating across the lexicon, we do not have a good sense of whether there are systematic differences between alignment at different levels.

Futhermore, positive alignment is treated as an inherently good thing, but there is clearly a limit to its goodness, as alignment is inherently backward-looking, while the general goal of a conversation is to exchange information that is not already known by both parties, and inherently forward-looking goal. There are suggestive results that alignment based on function words, which can stay constant even as the topic changes, is more appropriate than alignment based on all words for predicting performance in a decision-making task \cite{FusaroliEtAl2012}, and some recent work on accommodation has limited itself to ``non-topical'' word categories \cite{DNMGamonDumais2011,DoyleYurovskyFrank2016}.  

\section{Measures of alignment}
Multiple metrics for linguistic alignment have been used in previous work, which fall into two basic categories: distributional and conditional. The distributional methods, such as Linguistic Style Matching (LSM) \cite{NiederhofferPennebaker2002,IrelandEtAl2011} and the Zelig Quotient \cite{JonesEtAl2014}, calculate the similarity between the rate of usage of words or word categories between the conversation participants. Conditional metrics, such as Local Linguistic Alignment (LLA) \cite{FusaroliEtAl2012,WangReitterYen2014} and the metric used by \cite{DNMGamonDumais2011}, look at how a message conditions its reply, with convergence indicated by elevated word use in the reply when that word was in the preceding message. This paper extends a recent conditional metric, the Hierarchical Alignment Model \cite{DoyleYurovskyFrank2016}.

\paragraph{Distributional methods} [brief overview of LSM for completeness]


\paragraph{By-message conditional methods} By-message conditional methods rest on a binary view of utterances. If HAM is being used to assess alignment on pronouns, for instance, Bob aligns to Alice in the HAM model if his replies are more likely to contain a pronoun when in response to a message from Alice that contains a pronoun. An example of positive HAM alignment is shown in the table below:

\begin{center}
\begin{tabular}{|c||c|c|}
\hline 
& Bob's reply & \\
\hline
Alice's message & has pronoun & no pronoun \\
has pronoun & 8 & 2\\
no pronoun & 5 & 5\\
\hline
\end{tabular}
\end{center}

Here, Alice sends 10 messages that contain at least one pronoun, and 8 of Bob's replies contain at least one pronoun.  But Alice also sends 10 messages that don't contain any pronouns, and only 5 of Bob's replies to these contain pronouns. Alignment is this increased likelihood of a pronoun-containing reply to a pronoun-containing message.

Different models quantify this alignment slightly differently.  \cite{DNMGamonDumais2011} propose a subtractive conditional probability model, where alignment is the difference between the likelihood of a pronoun-containing reply to a pronoun-containing message and the probability of a pronoun-containing reply to any message:

\begin{equation}
align_{SCP} = p(B|A) - p(B)
\end{equation}

\cite{DoyleYurovskyFrank2016} show that this measure can be affected by the overall frequency of the category being aligned on. They propose the Hierarchical Alignment Model (HAM), which quantifies this alignment as a linear effect on the log-odds of a reply containing the relevant marker (e.g., a pronoun), similar to a linear predictor in a logistic regression:\footnote{Because the HAM defines a Bayesian inference structure for alignment, the inferred alignment value depends on the prior and number of message observed, so unlike the other measures, this equality is only approximate.}

\begin{equation}
align_{HAM} \approx logit^{-1}(p(B|A)) - logit^{-1}(p(B|\neg A))
\end{equation}

Both of these binarized conditional methods, though, depend on the assumption that all messages have similar, and small, numbers of words. The probability that a message contains at least one of any marker of interest is of course dependent on the message's length, so if messages vary substantially in their length, these alignment values can be at least noisy, if not biased. They are also not robust as messages increase in length, since the likelihood that a message contains any marker approaches 1 as message length increases.

\paragraph{By-word conditional methods} A solution to this is simply to shift from binarized data to count data. Instead of modeling whether or not a reply contains a marker of interest, we can model that marker's frequency within replies to messages that do or do not contain the marker.  Local Linguistic Alignment (LLA) \cite{FusaroliEtAl2012,WangReitterYen2014} and the lexical similarity (LS) measure of \cite{HealeyPurverHowes2014}, are two examples that estimate the proportion of the preceding message that appear in the reply. LLA is shown below, but LS is similar:

\begin{equation}
align_{LLA} = \frac{\sum_{w_i \in M_b} \delta(w_i \in M_a)}{length(M_a)length(M_b)}
\end{equation}

In LLA, alignment is the number of word tokens ($w_i$) that appear in both the message ($M_a$) and the reply ($M_b$) are divided by the product of the total number of word tokens in the message and reply. 

These measures have an aspect of conditionality, as they only count words that appear in both the message and the reply, but they lack baselining, one of \cite{DoyleYurovskyFrank2016}'s desired features in an alignment measure.  They also have inherent length dependence, as the maximum alignment estimate is only possible when the reply is shorter than the message.\footnote{Proof in Supplemental?}

We need, therefore, an alignment measure that has the benefits of the existing by-message conditional models (HAM outperformed SCP, LLA, and LSM in simulations in \cite{DoyleYurovskyFrank2016}) while gaining the length-robustness of a by-word conditional method.  A simple change to the HAM framework satisfies this goal.

\section{The Word-Based Hierarchical Alignment Model (WHAM)}

The Hierarchical Alignment Model (HAM) was proposed by \cite{DoyleYurovskyFrank2016} as a way to increase the robustness of conditional alignment metrics to sparse data and rare words. HAM conceptualizes alignment as the increase in the likelihood that a reply will contain a ``marker''---a word or word category---given that the preceding message contained it compared to when the preceding message did not contain it, as discussed above.

The HAM framework makes a substantial simplification: it treats each message as a binary variable, either containing or not containing the word of interest. This approach follows that of \cite{DNMGamonDumais2011}, who found alignment affects despite the simplification, and may be appropriate for data such as the Twitter dataset used in that paper, which has a 140-character limit and thus ensures all messages will be short, rarely containing more than one instance of a word. However, in looking at more natural dialogues, such as phone conversations, length may vary substantially between messages.  As such, we need a framework that is able to handle different message lengths.

We propose the Word-Based Hierarchical Alignment Model (WHAM) to address this. Like HAM, this framework assumes that replies are shaped by whether or not they are in reply to a message that contained the marker of interest. But where the HAM framework only looks at whether or not the reply contains the marker, the WHAM framework looks at the marker token frequencies within the reply.  For each marker, each reply is treated as a sample of independent draws from a binomial distribution. The binomial probability is dependent on whether the reply is responding to a message that does or does not contain the marker.

[Graphical model and a re-vamp of the model outline paragraph from WWW  to come.]

\begin{center}
\begin{tabular}{|c|}
\hline 
Generative Model \\
\hline
Alice says $x$, Bob wants to reply. \\
If $m \not\in x$, then $p(B_m|A_m) = \mu^{base}(m)$ \\
If $m \in x$, then $p(B_m|\neg A_m) = \mu^{align}(m)$ \\
\hline
$\mu^{base}(m) = logit^{-1}(\eta^{base}(m))$ \\
$\mu^{align}(m) = logit^{-1}(\eta^{base}(m)+\eta^{align}(m))$ \\
\hline
\end{tabular}
\end{center}

\section{Experiment 1}

\subsection{Levels of alignment}

We want to examine the interaction of two levels of alignment. The first is lexical-level alignment, looking at how the presence of a word in a message increases its likelihood of appearing in the reply.  The second is category-level alignment, looking at how the presence of a word in a message increases the likelihood of it or any other member of that category appearing in the reply.  These categories generally correspond to syntactic classes (pronouns, conjunctions) or broad conceptual classes (inclusive words, negative emotions)   Work on by-word conditional alignment has tended to focus on the lexical level, while distributional and by-message conditional alignment work has focused on the categorical level.

Some recent work has explored interactions between these levels. \citeNP{HealeyPurverHowes2014} treat lexical alignment as the baseline and find that turn-by-turn syntactic alignment is actually slightly lower than lexical alignment would predict. On the other hand, \citeNP{XuReitter2015} argue for LLA as a good alignment measure in part because of its high correlation between lexical and syntactic alignment, under the assumption that alignment at all levels is a communicative goal \cite{PickeringGarrod2004}. A major goal of this experiment is thus to investigate whether lexical- and categorical-level alignment point in the same direction.

Furthermore, we are interested in explicitly tracking the influence of lexical alignment on categorical alignment, to see whether previous results showing categorical alignment are just due to the lexical alignments of the words within the category, as \citeNP{HealeyPurverHowes2014}'s results would suggest.  If categorical alignment is a real effect over and above lexical alignment, then the presence of a word in a message should not only increase the chance of seeing that word in the reply, but also other words in its category. Intuitively, category alignment must be no less than the mean lexical alignment of words in the category, since each instance of lexical agreement is also an instance of category agreement.\footnote{More precisely, the weighted mean given lexical frequency.} 

\begin{table}[h]
\begin{center}
\begin{tabular}{|c||c|c|c|}
\hline 
%\bf & \bf \multicolumn{3}{|c|}{Reply} \\ \hline
\bf Message & $\emptyset$ & \textit{he} & \textit{she} \\ \hline
$\emptyset$ & 25 & 25 & 25\\
\textit{he} & 20 & 50 & 10 \\
\textit{she} & 20 & 10 & 50 \\
\hline
\end{tabular}
\end{center}
\caption{\label{table:cnw-example1} A case where lexical alignment surpasses categorical alignment due to non-independence between the words.}
\end{table}

However, interactions between lexical items within a category can cause the lexical alignment to actually be less than the category alignment. Table \ref{table:cnw-example1} illustrates this with a theoretical distribution over the pronouns \textit{he} and \textit{she}; one use of the pronoun \textit{he} makes another use more likely (\textit{Did he like the movie? Yeah, he loved it.}) while also reducing the likelihood of \textit{he}, since the topic of conversation is now a male, and vice versa for \textit{she}. For both \textit{he} and \textit{she}, the lexical alignment is approximately $logit^{-1}(p(B|A)-p(B|\neg A)) = logit^{-1}(\frac{50}{80}-\frac{25}{75}) \approx 1.2$, but categorical alignment is approximately $logit^{-1}(\frac{120}{160}-\frac{50}{75}) \approx 0.4$. 

Lexical alignment can differ from categorical alignment for a variety of reasons, so we consider three quantities: the lexical and categorical alignments, but also the ``category-not-word'' (CNW) alignment: the increased likelihood of seeing another member of the category other than the target word. Separating these three factors is complex, and the CNW alignment is not simply the categorical alignment minus the lexical alignment.

\subsection{Category-not-word Alignment}






%\section*{Acknowledgments}
%
%The acknowledgments should go immediately before the references.  Do
%not number the acknowledgments section. Do not include this section
%when submitting your paper for review.

% include your own bib file like this:
%\bibliographystyle{acl}
%\bibliography{acl2016}
\bibliography{library}
\bibliographystyle{acl2016}

\appendix

\section{Supplemental Material}
\label{sec:supplemental}

(Temporary collection of material that I'm considering adding as supplemental material -- separate from the paper, doesn't count against 8-page limit. [references also don't count against limit])

\begin{table}[h]
\begin{center}
\begin{tabular}{|c||c|c|c|c|}
\hline 
%\bf & \bf \multicolumn{4}{c}{Reply} \\ \hline
\bf Message & \{$\emptyset$\} & \{X\} & \{Y\} & \{X,Y\} \\ \hline
\{$\emptyset$\} &  160 & 20 & 10 & 10\\
\{X\} & 140 & 30 & 20 & 10 \\
\{Y\} & 170 & 10 & 15 & 5 \\
\hline
\end{tabular}
\end{center}
\caption{\label{table:cnw-example2} Another case where (mean lexical) > categorical alignment.}
\end{table}

[Proof that LLA and Healey's measure of lexical similarity can depend on message/reply length.]

\end{document}
